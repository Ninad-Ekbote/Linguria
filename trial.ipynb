{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import build_transformer\n",
    "from dataset import BilingualDataset, causal_mask\n",
    "from config import get_config, get_weights_file_path, latest_weights_file_path\n",
    "\n",
    "import torchtext; torchtext.disable_torchtext_deprecation_warning()\n",
    "import torchtext.datasets as datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Huggingface datasets and tokenizers\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds(config):\n",
    "    # It only has the train split, so we divide it overselves\n",
    "    ds_raw = load_dataset(f\"{config['datasource']}\", f\"{config['lang_src']}-{config['lang_tgt']}\", split='train')\n",
    "\n",
    "    # Build tokenizers\n",
    "    tokenizer_src = get_or_build_tokenizer(config, ds_raw, config['lang_src'])\n",
    "    tokenizer_tgt = get_or_build_tokenizer(config, ds_raw, config['lang_tgt'])\n",
    "\n",
    "    # Keep 90% for training, 10% for validation\n",
    "    train_ds_size = int(0.9 * len(ds_raw))\n",
    "    val_ds_size = len(ds_raw) - train_ds_size\n",
    "    train_ds_raw, val_ds_raw = random_split(ds_raw, [train_ds_size, val_ds_size])\n",
    "\n",
    "    train_ds = BilingualDataset(train_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
    "    val_ds = BilingualDataset(val_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
    "\n",
    "    # Find the maximum length of each sentence in the source and target sentence\n",
    "    max_len_src = 0\n",
    "    max_len_tgt = 0\n",
    "\n",
    "    for item in ds_raw:\n",
    "        src_ids = tokenizer_src.encode(item['translation'][config['lang_src']]).ids\n",
    "        tgt_ids = tokenizer_tgt.encode(item['translation'][config['lang_tgt']]).ids\n",
    "        max_len_src = max(max_len_src, len(src_ids))\n",
    "        max_len_tgt = max(max_len_tgt, len(tgt_ids))\n",
    "\n",
    "    print(f'Max length of source sentence: {max_len_src}')\n",
    "    print(f'Max length of target sentence: {max_len_tgt}')\n",
    "    \n",
    "\n",
    "    train_dataloader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n",
    "    val_dataloader = DataLoader(val_ds, batch_size=1, shuffle=True)\n",
    "\n",
    "    return train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_build_tokenizer(config, ds, lang):\n",
    "    tokenizer_path = Path(config['tokenizer_file'].format(lang))\n",
    "    if not Path.exists(tokenizer_path):\n",
    "        # Most code taken from: https://huggingface.co/docs/tokenizers/quicktour\n",
    "        tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "        tokenizer.pre_tokenizer = Whitespace()\n",
    "        trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"], min_frequency=2)\n",
    "        tokenizer.train_from_iterator(get_all_sentences(ds, lang), trainer=trainer)\n",
    "        tokenizer.save(str(tokenizer_path))\n",
    "    else:\n",
    "        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n",
    "    return tokenizer\n",
    "\n",
    "def get_all_sentences(ds, lang):\n",
    "    for item in ds:\n",
    "        yield item['translation'][lang]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lauda\n"
     ]
    }
   ],
   "source": [
    "ds_raw = load_dataset(f\"{config['datasource']}\", f\"{config['lang_src']}-{config['lang_tgt']}\", split='train')\n",
    "tokenizer_src = get_or_build_tokenizer(config, ds_raw, config['lang_src'])\n",
    "print(\"Lauda\")\n",
    "k = torch.tensor([tokenizer_src.token_to_id('[SOS]')], dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = torch.tensor([tokenizer_src.token_to_id(\"[SOS]\")], dtype=torch.int64)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_src.token_to_id('[SOS]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\anacond\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: filelock in d:\\anacond\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\anacond\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in d:\\anacond\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anacond\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\anacond\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in d:\\anacond\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\anacond\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anacond\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anacond\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.5.0-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in d:\\anacond\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\anacond\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in d:\\anacond\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anacond\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\anacond\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in d:\\anacond\\lib\\site-packages (from torch) (69.5.1)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anacond\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anacond\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.5.0-cp312-cp312-win_amd64.whl (203.1 MB)\n",
      "   ---------------------------------------- 0.0/203.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/203.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/203.1 MB 325.1 kB/s eta 0:10:25\n",
      "   ---------------------------------------- 0.1/203.1 MB 901.1 kB/s eta 0:03:46\n",
      "   ---------------------------------------- 0.5/203.1 MB 3.0 MB/s eta 0:01:07\n",
      "   ---------------------------------------- 1.8/203.1 MB 8.1 MB/s eta 0:00:25\n",
      "    --------------------------------------- 4.2/203.1 MB 15.7 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 6.4/203.1 MB 20.3 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 9.7/203.1 MB 26.8 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 12.2/203.1 MB 54.7 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 15.1/203.1 MB 59.5 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 17.4/203.1 MB 54.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 20.3/203.1 MB 54.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 23.2/203.1 MB 59.5 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 25.7/203.1 MB 54.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 28.4/203.1 MB 54.4 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 31.1/203.1 MB 54.4 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 33.6/203.1 MB 59.5 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 36.6/203.1 MB 54.7 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 39.3/203.1 MB 54.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 42.0/203.1 MB 59.8 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 44.6/203.1 MB 59.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 47.3/203.1 MB 59.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 50.1/203.1 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 52.9/203.1 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 55.7/203.1 MB 59.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 58.6/203.1 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 61.4/203.1 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 64.1/203.1 MB 59.8 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 66.8/203.1 MB 65.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 69.6/203.1 MB 59.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 72.3/203.1 MB 59.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 75.2/203.1 MB 59.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 78.0/203.1 MB 59.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 80.7/203.1 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 83.2/203.1 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 85.8/203.1 MB 59.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 88.5/203.1 MB 54.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 91.3/203.1 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 94.0/203.1 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 97.0/203.1 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 99.5/203.1 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------- ------------------- 102.1/203.1 MB 59.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------ 104.7/203.1 MB 59.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------ 107.6/203.1 MB 54.7 MB/s eta 0:00:02\n",
      "   --------------------- ----------------- 109.9/203.1 MB 54.7 MB/s eta 0:00:02\n",
      "   --------------------- ----------------- 112.6/203.1 MB 54.7 MB/s eta 0:00:02\n",
      "   ---------------------- ---------------- 115.4/203.1 MB 54.7 MB/s eta 0:00:02\n",
      "   ---------------------- ---------------- 118.1/203.1 MB 54.4 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 120.9/203.1 MB 65.6 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 123.7/203.1 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 126.5/203.1 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 129.0/203.1 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 131.6/203.1 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 134.4/203.1 MB 59.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 137.2/203.1 MB 59.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 140.0/203.1 MB 59.5 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 142.8/203.1 MB 59.5 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 145.5/203.1 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 148.1/203.1 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 150.9/203.1 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 154.0/203.1 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 156.4/203.1 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 159.3/203.1 MB 59.8 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 162.2/203.1 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 164.8/203.1 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 167.5/203.1 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 169.3/203.1 MB 54.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 172.9/203.1 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 175.5/203.1 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 178.1/203.1 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 180.8/203.1 MB 59.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 183.6/203.1 MB 54.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 186.3/203.1 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 189.0/203.1 MB 54.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 191.9/203.1 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 194.3/203.1 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 197.2/203.1 MB 54.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.9/203.1 MB 54.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.5/203.1 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.1/203.1 MB 59.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.1/203.1 MB 59.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.1/203.1 MB 59.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.1/203.1 MB 59.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.1/203.1 MB 59.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.1/203.1 MB 59.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.1/203.1 MB 59.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.1/203.1 MB 59.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.1/203.1 MB 59.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.1/203.1 MB 59.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.1/203.1 MB 59.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 203.1/203.1 MB 15.2 MB/s eta 0:00:00\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Installing collected packages: sympy, torch\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "Successfully installed sympy-1.13.1 torch-2.5.0\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
